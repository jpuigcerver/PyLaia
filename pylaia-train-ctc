#!/usr/bin/env python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import collections
import editdistance
import itertools
import laia.data
import laia.models.htr
import numpy as np
import torch

from collections import OrderedDict
from operator import mul
from torch.autograd import Variable
from torch.utils.data import DataLoader
import torch.nn as nn
from torch.nn.utils.rnn import PackedSequence, pad_packed_sequence, pack_padded_sequence
from warpctc_pytorch import CTCLoss

class TextToTensor(object):
    def __init__(self, sym2int):
        assert isinstance(sym2int, dict)
        self._sym2int = sym2int

    def __call__(self, x):
        x = [self._sym2int[c] for c in x]
        return x

class ImageToTensor(object):
    def __init__(self, invert=False, mode='F'):
        assert mode in ('F', 'L', 'RGB', 'RGBA')
        self._invert = invert
        self._mode = mode

    def __call__(self, x):
        x = x.convert(self._mode)
        if self._invert:
            x = x.invert()
        x = np.asarray(x, dtype=np.float32)
        if len(x.shape) != 3:
            x = np.expand_dims(x, axis=-1)
        x = np.transpose(x, (2, 0, 1))
        return torch.from_numpy(x / 255.0)

def LoadSymbolsTable(f):
    if isinstance(f, (str, unicode)):
        f = open(f, 'r')
    sym2int, int2sym = OrderedDict(), OrderedDict()
    for n, line in enumerate(f, 1):
        line = line.split()
        s, v = line[0], int(line[1])
        sym2int[s] = v
        int2sym[v] = s
    f.close()
    assert len(sym2int) == len(int2sym), (
        'Repeated symbols or IDs in symbols table "%s"' % f.name)
    return sym2int, int2sym

def GreedyDecoder(y, ys):
    # Shape y: T x N x L
    _, idx = y.max(dim=2)
    idx = idx.t().tolist()
    y = [idx_n[:int(ys[n])] for n, idx_n in enumerate(idx)]
    y = [reduce(lambda z, x: z if z[-1] == x else z + [x], y_n[1:], [y_n[0]])
         for y_n in y]
    y = [filter(lambda x: x != 0, y_n) for y_n in y]
    return y


def ComputeBatchErrorRate(batch_txt_ref, batch_txt_hyp):
    nerr, tlen = 0, 0
    for tr, th in zip(batch_txt_ref, batch_txt_hyp):
        nerr += editdistance.eval(tr, th)
        tlen += len(tr)
    return float(nerr) / float(tlen)



if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch_size', type=int, default=8,
                        help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=0.0005,
                        help='Learning rate')
    parser.add_argument('--momentum', type=float, default=None,
                        help='Momentum')
    parser.add_argument('--max_updates', type=int, default=None,
                        help='Maximum number of training updates (iterations)')
    parser.add_argument('--gpu', type=int, default=1,
                        help='Use this GPU (starting from 1)')
    parser.add_argument('syms')
    parser.add_argument('tr_img_dir')
    parser.add_argument('tr_txt_table')
    parser.add_argument('va_txt_table')

    args = parser.parse_args()

    sym2int, int2sym = LoadSymbolsTable(args.syms)

    tr_ds = laia.data.TextImageFromTextTableDataset(
        args.tr_txt_table, args.tr_img_dir,
        img_transform=ImageToTensor(),
        txt_transform=TextToTensor(sym2int))
    tr_ds_loader = DataLoader(tr_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)),
                              shuffle=True)

    va_ds = laia.data.TextImageFromTextTableDataset(
        args.va_txt_table, args.tr_img_dir,
        img_transform=ImageToTensor(),
        txt_transform=TextToTensor(sym2int))
    va_ds_loader = DataLoader(va_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)))


    model = laia.models.htr.CnnRnn(1, 84, [16, 16, 32, 32],
                                   [3] * 4,
                                   [1] * 4,
                                   [nn.LeakyReLU] * 4,
                                   [2, 2, 2, 0],
                                   [0.0] * 4,
                                   [False] * 4,
                                   256, 3, 0.5, 0.5, collapse='adaptive_max-8')

    if args.gpu:
        model.cuda(args.gpu - 1)

    ctc = CTCLoss()
    parameters = model.parameters()
    optimizer = torch.optim.RMSprop(parameters, lr=args.learning_rate,
                                    momentum=args.momentum)

    it, epoch = 0, 0
    training_done = False
    while not training_done:
        epoch = epoch + 1
        model.train()
        for batch in tr_ds_loader:
            it = it + 1
            if args.max_updates and it > args.max_updates:
                training_done = True
                break

            x = Variable(batch['img'].data)
            xs = batch['img'].sizes[:,1:]
            if args.gpu:
                x = x.cuda(args.gpu - 1)
                #xs = xs.cuda(args.gpu - 1)

            y = model(laia.data.PaddedTensor(x, xs))
            y, ys = pad_packed_sequence(y)

            targets = list(itertools.chain.from_iterable(batch['txt']))
            targets_size = map(lambda x: len(x), batch['txt'])

            targets = Variable(torch.IntTensor(targets), requires_grad=False)
            targets_size = Variable(torch.IntTensor(targets_size),
                                    requires_grad=False)
            ys = Variable(torch.IntTensor(ys), requires_grad=False)

            loss = ctc(y, targets, ys, targets_size)
            loss = (loss / ys.type(torch.FloatTensor)).mean()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        model.eval()
        va_ref = []
        va_hyp = []
        for batch in va_ds_loader:
            x = Variable(batch['img'].data)
            xs = batch['img'].sizes[:,1:]
            if args.gpu:
                x = x.cuda(args.gpu - 1)

            y = model(laia.data.PaddedTensor(x, xs))
            y, ys = pad_packed_sequence(y)
            va_ref.extend(batch['txt'])
            va_hyp.extend(GreedyDecoder(y.data, ys))
        va_cer = ComputeBatchErrorRate(va_ref, va_hyp)

        tr_ref = []
        tr_hyp = []
        for batch in tr_ds_loader:
            x = Variable(batch['img'].data)
            xs = batch['img'].sizes[:,1:]
            if args.gpu:
                x = x.cuda(args.gpu - 1)

            y = model(laia.data.PaddedTensor(x, xs))
            y, ys = pad_packed_sequence(y)
            tr_ref.extend(batch['txt'])
            tr_hyp.extend(GreedyDecoder(y.data, ys))

        tr_cer = ComputeBatchErrorRate(tr_ref, tr_hyp)
        print('EPOCH %d %6.2f %6.2f' % (epoch, tr_cer * 100, va_cer * 100))
